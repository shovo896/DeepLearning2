{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec3d4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "mnist=tf.keras.datasets.mnist \n",
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3ea4a",
   "metadata": {},
   "source": [
    "preprocessing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beabab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols=-28,28 \n",
    "x_train=x_train.reshape(x_train.shape[0],rows,cols,1)\n",
    "x_test=x_test.reshape(x_test.shape[0],rows,cols,1)\n",
    "input_shape=(rows,cols,1)\n",
    "x_train=x_train.astype('float32')\n",
    "x_test=x_test.astype('float32')\n",
    "x_train=x_train/255.0\n",
    "x_test=x_test/255.0 \n",
    "\n",
    "y_train=tf.keras.utils.to_categorical(y_train,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e79e3",
   "metadata": {},
   "source": [
    "define the Lenet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf14b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lenet(input_shape):\n",
    "       model=tf.keras.Sequential()\n",
    "       # c1 convolutional layer \n",
    "       model.add(tf.keras.layers.Conv2D(fileters=6,strides=(1,1),kernel_size=(5,5),activation='tanh',input_shape=input_shape))\n",
    "       model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "       #c3 convolution layer \n",
    "       model.add(tf.keras.layers.Conv2D(filters=6,strides=(1,1),kernel_size=(5,5),activation='tanh'))\n",
    "       #subsampling layer \n",
    "       model.add(tf.add.layers.AveragePooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "       model.add(tf.keras.layers.Dense(units=120,activation='tanh'))\n",
    "\n",
    "       model.add(tf.keras.layers.Flatten())\n",
    "       model.add(tf.keras.layers.Dense(units=84,actiavtion='tanh'))\n",
    "\n",
    "       model.add(tf.keras.layers.Dense(units=10,activation='softmax'))\n",
    "\n",
    "       return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b8528",
   "metadata": {},
   "source": [
    "evaluate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3683d173",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Conv2D.__init__() missing 1 required positional argument: 'filters'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m lenet=\u001b[43mbuild_lenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m lenet.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      4\u001b[39m epochs=\u001b[32m10\u001b[39m \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mbuild_lenet\u001b[39m\u001b[34m(input_shape)\u001b[39m\n\u001b[32m      2\u001b[39m model=tf.keras.Sequential()\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# c1 convolutional layer \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m model.add(\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtanh\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      5\u001b[39m model.add(tf.keras.layers.AveragePooling2D(pool_size=(\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m),strides=(\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m)))\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#c3 convolution layer \u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: Conv2D.__init__() missing 1 required positional argument: 'filters'"
     ]
    }
   ],
   "source": [
    "lenet=build_lenet(input_shape)\n",
    "\n",
    "lenet.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "epochs=10 \n",
    "history=lenet.fit(x_train,y_train,epochs=epochs,batch_size=128,verbose=1)\n",
    "if len(y_test.shape) != 2 or y_test.shape[1] !=10 : \n",
    "       y_test=tf.keras.utils.to_categorical(y_test,10)\n",
    "loss,acc=lenet.evaluate(x_test,y_test)\n",
    "print('Accuracy:',acc)\n",
    "\n",
    "\n",
    "x_train=x_train.reshape(x_train.shape[0],28,28)\n",
    "print('Training Data',x_train.shape,y_train.shape)\n",
    "x_test=x_test.reshape(x_test.shape[0],28,28)\n",
    "\n",
    "# plot the image \n",
    "image_index=8888 \n",
    "plt.imshow(x_test[image_index].reshape(28,28),cmap='Greys')\n",
    "\n",
    "pred=lenet.predict(x_test[image.index].reshape(1,rows,cols,1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6b42e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lenet(input_shape):\n",
    "  # Define Sequential Model\n",
    "  model = tf.keras.Sequential()\n",
    "\n",
    "  # C1 Convolution Layer\n",
    "  model.add(tf.keras.layers.Conv2D(filters=6, strides=(1,1), kernel_size=(5,5), activation='tanh', input_shape=input_shape))\n",
    "\n",
    "  # S2 SubSampling Layer\n",
    "  model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "  # C3 Convolution Layer\n",
    "  model.add(tf.keras.layers.Conv2D(filters=6, strides=(1,1), kernel_size=(5,5), activation='tanh'))\n",
    "\n",
    "  # S4 SubSampling Layer\n",
    "  model.add(tf.keras.layers.AveragePooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "  # C5 Fully Connected Layer\n",
    "  model.add(tf.keras.layers.Dense(units=120, activation='tanh'))\n",
    "\n",
    "  # Flatten the output so that we can connect it with the fully connected layers by converting it into a 1D Array\n",
    "  model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "  # FC6 Fully Connected Layers\n",
    "  model.add(tf.keras.layers.Dense(units=84, activation='tanh'))\n",
    "\n",
    "  # Output Layer\n",
    "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "554cce90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shuvo\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert '(-28, 28, 1)' to a shape. Negative dimensions are not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m lenet = \u001b[43mbuild_lenet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[32m      4\u001b[39m lenet.compile(optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m, loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m, metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mbuild_lenet\u001b[39m\u001b[34m(input_shape)\u001b[39m\n\u001b[32m      3\u001b[39m model = tf.keras.Sequential()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# C1 Convolution Layer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtanh\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# S2 SubSampling Layer\u001b[39;00m\n\u001b[32m      9\u001b[39m model.add(tf.keras.layers.AveragePooling2D(pool_size=(\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m), strides=(\u001b[32m2\u001b[39m,\u001b[32m2\u001b[39m)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\models\\sequential.py:88\u001b[39m, in \u001b[36mSequential.add\u001b[39m\u001b[34m(self, layer, rebuild)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._layers:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(layer, \u001b[33m\"\u001b[39m\u001b[33m_input_shape_arg\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m         \u001b[38;5;28mself\u001b[39m.add(\u001b[43mInputLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_input_shape_arg\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# If we are passed a Keras tensor created by keras.Input(), we\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# extract the input layer from its keras history and use that.\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(layer, \u001b[33m\"\u001b[39m\u001b[33m_keras_history\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\layers\\core\\input_layer.py:92\u001b[39m, in \u001b[36mInputLayer.__init__\u001b[39m\u001b[34m(self, shape, batch_size, dtype, sparse, ragged, batch_shape, input_tensor, optional, name, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou must pass a `shape` argument.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m         shape = \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstandardize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m         batch_shape = (batch_size,) + shape\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m._batch_shape = backend.standardize_shape(batch_shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\keras\\src\\backend\\common\\variables.py:617\u001b[39m, in \u001b[36mstandardize_shape\u001b[39m\u001b[34m(shape)\u001b[39m\n\u001b[32m    612\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    613\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to a shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    614\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound invalid entry \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m of type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    615\u001b[39m         )\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e < \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    618\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot convert \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m to a shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    619\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mNegative dimensions are not allowed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    620\u001b[39m         )\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m shape\n",
      "\u001b[31mValueError\u001b[39m: Cannot convert '(-28, 28, 1)' to a shape. Negative dimensions are not allowed."
     ]
    }
   ],
   "source": [
    "lenet = build_lenet(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "lenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# We will be allowing 10 itterations to happen\n",
    "epochs = 10\n",
    "history = lenet.fit(x_train, y_train, epochs=epochs,batch_size=128, verbose=1)\n",
    "\n",
    "# Check Accuracy of the Model\n",
    "# Transform labels to one hot encoding\n",
    "if len(y_test.shape) != 2 or y_test.shape[1] != 10:\n",
    "  y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "loss ,acc= lenet.evaluate(x_test, y_test)\n",
    "print('Accuracy : ', acc)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28,28)\n",
    "print('Training Data', x_train.shape, y_train.shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28,28)\n",
    "print('Test Data', x_test.shape, y_test.shape)\n",
    "\n",
    "# Plot the Image\n",
    "image_index = 8888\n",
    "plt.imshow(x_test[image_index].reshape(28,28), cmap='Greys')\n",
    "\n",
    "# Make Prediction\n",
    "pred = lenet.predict(x_test[image_index].reshape(1, rows, cols, 1 ))\n",
    "print(pred.argmax())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
